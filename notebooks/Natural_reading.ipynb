{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Natural reading task*\n",
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from mayavi import mlab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dirs needed for all visualizations\n",
    "experiment_dir = '../natural_reading/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../natural_reading/evoked/average-ave.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 96)  idle\n",
      "    Found the data of interest:\n",
      "        t =    -250.00 ...     600.00 ms (Grand average (n = 39))\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 39 - aspect type = 100\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "# Read average evoked file\n",
    "evoked_dir = op.join(experiment_dir, 'evoked')\n",
    "evoked_file =  op.join(evoked_dir, 'average-ave.fif')\n",
    "average_evoked = mne.read_evokeds(evoked_file, condition = 0, baseline=None, proj=False,).crop(-0.050,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cca86110e847cfa66cff964fd7b7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac676fdf5e3a463a84a07c4d16dd6ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0d47e7de294e30a8500c0c3222e48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot evoked potentials \n",
    "fig0 = average_evoked.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21f38106f454a4294ad3b6fe09cfbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot only in one time window \n",
    "average_evoked.crop(0.0,0.450) # change time-window here\n",
    "fig1 = average_evoked.plot(spatial_colors=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise_cov = 'with_non_reg_noise_cov'\n",
    "method = 'MNE'\n",
    "views = ['caudal', 'lateral']\n",
    "hemis = ['both', 'lh'] # looped together with views, as a tuple\n",
    "\n",
    "# Select time points to show\n",
    "time_points = np.linspace(0.060, 0.130, 8)\n",
    "time_sections = [0,2,4,6] # index of first subplot in figure, 2 images are shown per figure\n",
    "\n",
    "mlab.options.offscreen = True\n",
    "\n",
    "average_stc_file = op.join(experiment_dir, noise_cov, method, 'average')\n",
    "average_stc = mne.read_source_estimate(average_stc_file, 'fsaverage')\n",
    "\n",
    "for t in time_sections:\n",
    "    for view, hemi in zip(views, hemis):\n",
    "        fig1, axs1 = plt.subplots(1,2, sharex=True, sharey = True)\n",
    "#         fig1.suptitle(condition.capitalize() + ' condition')\n",
    "        surfer_kwargs = dict(hemi=hemi, clim=dict(kind='value', lims=[6.5e-12, 7.0e-12, 1.6e-11 ]),\n",
    "                             views=view, time_unit='s', smoothing_steps=5, colorbar = False, size = 500, time_label = None)\n",
    "        for col,time_point in enumerate(time_points[t:(t+2)]):\n",
    "            brain = average_stc.plot(initial_time = time_point, **surfer_kwargs)\n",
    "            img = mlab.screenshot()\n",
    "            mlab.close()\n",
    "            axs1[col].imshow(img)\n",
    "            axs1[col].set_axis_off()\n",
    "            axs1[col].set_title(str(int(time_point*1000))+ ' ms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive figure with time viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.25363966 0.30715286 1.06028318]\n"
     ]
    }
   ],
   "source": [
    "method = 'eLORETA'\n",
    "# lims = [2, 5, 31 ]\n",
    "noise_cov = 'with_non_reg_noise_cov'\n",
    "views = ['lat','caudal','ventral']\n",
    "mlab.options.offscreen = False\n",
    "\n",
    "stc_file = op.join(experiment_dir, noise_cov, method, 'average')\n",
    "stc = mne.read_source_estimate(stc_file, 'fsaverage')\n",
    "tview_kwargs = dict(hemi='split', #clim=dict(kind='value', lims=lims),\n",
    "                     views=views, time_unit='s', smoothing_steps=5, colorbar = True, size = 1400, \n",
    "                     initial_time = 0.0, time_viewer = True)\n",
    "brain = stc.plot(**tview_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = 0.220\n",
    "tmax = 0.300\n",
    "method = 'MNE'\n",
    "lims = [6.5e-12, 7.0e-12, 1.6e-11 ]\n",
    "noise_cov = 'with_non_reg_noise_cov'\n",
    "views = ['lat','caudal','ventral']\n",
    "video_file = 'NR_P2_'+ method +'.mov'\n",
    "\n",
    "mlab.options.offscreen = False\n",
    "stc_file = op.join(experiment_dir,noise_cov, method,'average')\n",
    "stc = mne.read_source_estimate(stc_file, 'fsaverage')\n",
    "video_kwargs = dict(hemi='split', clim=dict(kind='value', lims=lims),\n",
    "                     views=views, time_unit='s', smoothing_steps=5, colorbar = True, size = 1600)\n",
    "brain = stc.plot(**video_kwargs)\n",
    "brain.save_movie(video_file, tmin=tmin, tmax= tmax, time_dilation = 200, framerate = 24)\n",
    "mlab.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-hemisphere contrast in source space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast function\n",
    "def create_cross_hemi_contrast(stc, tmin = None, tmax = None):\n",
    "    \n",
    "    # Read files if input is string\n",
    "    if isinstance(stc, str):\n",
    "        stc = mne.read_source_estimate(stc, 'fsaverage')\n",
    "\n",
    "    # Crop\n",
    "    stc.crop(tmin, tmax)\n",
    "    \n",
    "    # Load FsAverage anatomy\n",
    "    fs_dir = fetch_fsaverage(verbose=False)\n",
    "    subjects_dir = op.dirname(fs_dir)\n",
    "    \n",
    "    # Morph the data to fsaverage_sym, for which we have left_right registrations:\n",
    "    stc = mne.compute_source_morph(stc,'fsaverage', 'fsaverage_sym', smooth=5, warn=True,\n",
    "                                   subjects_dir=subjects_dir).apply(stc)\n",
    "    # Compute a morph-matrix mapping the right to the left hemisphere,\n",
    "    # and vice-versa.\n",
    "    morph = mne.compute_source_morph(stc, 'fsaverage_sym', 'fsaverage_sym',\n",
    "                                     spacing=stc.vertices, warn=False,\n",
    "                                     subjects_dir=subjects_dir, xhemi=True,\n",
    "                                     verbose='error')  # creating morph map\n",
    "    stc_xhemi = morph.apply(stc)\n",
    "\n",
    "    # Create contrast\n",
    "    contrast = stc - stc_xhemi\n",
    "\n",
    "    # Return stc with contrast data\n",
    "    return contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive figure with time-viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.05290117 0.06464495 0.24552155]\n"
     ]
    }
   ],
   "source": [
    "tmin = 0.0\n",
    "tmax = 0.450\n",
    "method = 'eLORETA'\n",
    "noise_cov = 'with_non_reg_noise_cov'\n",
    "# STC files\n",
    "stc_file = op.join(experiment_dir, noise_cov, method, 'average')\n",
    "\n",
    "contrast = create_cross_hemi_contrast(stc_file, tmin = tmin, tmax = tmax) # create contrast stc\n",
    "\n",
    "lims = [1.5e-12, 1.5e-12, 6.5e-12]\n",
    "\n",
    "mlab.options.offscreen = False\n",
    "contrast_kwargs = dict(hemi='split', views=['lateral', 'caudal', 'ventral'], #clim=dict(kind='value', pos_lims=lims),\n",
    "                       initial_time= tmin, time_unit='s', size=(1200, 1200), smoothing_steps=5, time_viewer = True)\n",
    "\n",
    "brain = contrast.plot(**contrast_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
